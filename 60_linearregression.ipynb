{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.42587939698493 455.0 68.0 387.0\n",
      "count    398.000000\n",
      "mean       1.934259\n",
      "std        1.042698\n",
      "min        0.680000\n",
      "25%        1.042500\n",
      "50%        1.485000\n",
      "75%        2.620000\n",
      "max        4.550000\n",
      "Name: displacement, dtype: float64\n",
      "count    398.000000\n",
      "mean       0.235146\n",
      "std        0.078160\n",
      "min        0.090000\n",
      "25%        0.175000\n",
      "50%        0.230000\n",
      "75%        0.290000\n",
      "max        0.466000\n",
      "Name: mpg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# https://archive.ics.uci.edu/ml/datasets/auto+mpg\n",
    "autompg = pd.read_csv('auto_mpg.csv')\n",
    "autompg_disp = autompg['displacement'].astype(float)\n",
    "autompg_mpg = autompg['mpg'].astype(float)\n",
    "mean_disp = np.mean(autompg_disp)\n",
    "min_disp = np.min(autompg_disp)\n",
    "max_disp = np.max(autompg_disp)\n",
    "print(mean_disp, max_disp, min_disp, max_disp-min_disp)\n",
    "autompg_disp = autompg_disp.apply(lambda x:x/100)\n",
    "print(autompg_disp.describe())\n",
    "autompg_mpg = autompg_mpg.apply(lambda x: x/100)\n",
    "print(autompg_mpg.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "n_epochs = 3000\n",
    "display_step = 100\n",
    "train_X = np.asarray(autompg_disp)\n",
    "train_Y = np.asarray(autompg_mpg)\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getbatch(xval, yval, arraylength, batchsize=30):\n",
    "    count = 0 \n",
    "    while count < arraylength/batchsize:\n",
    "        random.seed(datetime.datetime.now())\n",
    "        randstart = random.randint(0, arraylength-batchsize-1)\n",
    "        count += 1\n",
    "        yield (xval[randstart:randstart+batchsize], yval[randstart:randstart+batchsize])\n",
    "\n",
    "# Test\n",
    "#for i in getbatch(train_X, train_Y, n_samples):\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.Variable(np.random.randn())\n",
    "b = tf.Variable(np.random.randn())\n",
    "\n",
    "# predicted is X*W+b. \n",
    "pred = tf.add(tf.multiply(X, W), b)\n",
    "\n",
    "# The cost function is ((predicted-actual)^2)/2*n_samples. \n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Add all ops that need to be initialized\n",
    "# The initilization needs to be run only after session is created\n",
    "# as in session.run(init) below.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Summary writer and its configuration\n",
    "writer = tf.summary.FileWriter(\"./logs\")\n",
    "tf.summary.scalar(\"Cost\", cost)\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0100 and cost = 0.526417911\n",
      "Epoch = 0200 and cost = 0.438049614\n",
      "Epoch = 0300 and cost = 0.388165623\n",
      "Epoch = 0400 and cost = 0.345071405\n",
      "Epoch = 0500 and cost = 0.306156367\n",
      "Epoch = 0600 and cost = 0.271642059\n",
      "Epoch = 0700 and cost = 0.241282418\n",
      "Epoch = 0800 and cost = 0.214207590\n",
      "Epoch = 0900 and cost = 0.190035298\n",
      "Epoch = 1000 and cost = 0.168596506\n",
      "Epoch = 1100 and cost = 0.149639815\n",
      "Epoch = 1200 and cost = 0.132979482\n",
      "Epoch = 1300 and cost = 0.118245579\n",
      "Epoch = 1400 and cost = 0.105099902\n",
      "Epoch = 1500 and cost = 0.093555912\n",
      "Epoch = 1600 and cost = 0.083107658\n",
      "Epoch = 1700 and cost = 0.073789187\n",
      "Epoch = 1800 and cost = 0.065613478\n",
      "Epoch = 1900 and cost = 0.058382567\n",
      "Epoch = 2000 and cost = 0.051937491\n",
      "Epoch = 2100 and cost = 0.046206564\n",
      "Epoch = 2200 and cost = 0.041139115\n",
      "Epoch = 2300 and cost = 0.036662053\n",
      "Epoch = 2400 and cost = 0.032622930\n",
      "Epoch = 2500 and cost = 0.029079694\n",
      "Epoch = 2600 and cost = 0.025937488\n",
      "Epoch = 2700 and cost = 0.023155289\n",
      "Epoch = 2800 and cost = 0.020649977\n",
      "Epoch = 2900 and cost = 0.018453028\n",
      "Epoch = 3000 and cost = 0.016516523\n",
      "The final W = 0.0958 and b = -0.0169\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for (x, y) in getbatch(train_X, train_Y, n_samples):\n",
    "            _, costval, merged_summary = sess.run([optimizer, cost, merged_summary_op], \n",
    "                                                  feed_dict={X: x, Y: y})\n",
    "        writer.add_summary(merged_summary, epoch)\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch = {:04d} and cost = {:.9f}\".format(epoch+1, c))\n",
    "\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    finalW = sess.run(W)\n",
    "    finalb = sess.run(b)\n",
    "    print(\"The final W = %0.4f and b = %0.4f\" %(finalW, finalb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening tensorboard\n",
    "\n",
    "In the command line, type \"tensorboard --logdir=./logs\"\n",
    "This will launch a local webserver at port 6006. Visit http://localhost:6006 in a browser. Then click on the label 'Cost' to see the graph.  You can make the graph larger by clicking on the rectangular button at the bottom left corner of the graph. You can zoom in to the graph by drawing a box around the region to zoom in. You can zoom out by double clicking the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
